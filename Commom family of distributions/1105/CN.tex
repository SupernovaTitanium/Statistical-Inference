\documentclass[../Distributions.tex]{subfiles}
\begin{document}
	\begin{center}
		\renewcommand{\arraystretch}{2}
		\begin{bfseries}
			\begin{tabular}{|c|}
				\hline
				Statistical Inference I \hfill Prof. Chin-Tsang Chiang\\
				\hspace{15em} {\large Lecture Notes 14} \hspace{15em}\ \\
				\lecdate \hfill Scribe: \scribe\\
				\hline
			\end{tabular}
			\renewcommand{\arraystretch}{1}
		\end{bfseries}
	\end{center}

\section{Continuous distribution}
\subsection{Uniform distribution}
In continuous regime, we define a uniform random variable on a close interval $[a,b]$, where $a<b$, and denote it as Uni($a,b$). If $X\sim$Uni($a,b$), then
\begin{itemize}
	\item $f_X(x|a,b) = \frac{1}{b-a}$
	\item $\mathbb{E}[X|a,b] = \frac{a+b}{2}$
	\item $Var[X|a,b] = \frac{(b-a)^2}{12}$
\end{itemize}

\subsection{Exponential family}
Here, we define three highly related continuous random variables: exponential, Weibull, and gamma. We first write down their distribution respectively, then introduce their relationship and properties.\\

\noindent{\bf Exponential}: Exponential random variable captures a single interleaving time of a Poisson process with frequency $1/\beta$. If $X\sim$exponential($\beta)$
$$f_X(x|\beta) = \frac{1}{\beta}e^{-x/\beta}\mathbf{1}_{(0,\infty)}(x)$$

\noindent{\bf Weibull}: If $Y=X^{1/\gamma}$, where $X\sim$exponential($\beta$) and $\gamma>0$, we say $Y$ has a Weibull($\beta,\gamma$) distribution.
$$f_Y(y|\beta,\gamma) = \frac{\gamma}{\beta}y^{\gamma-1}e^{-y^{\gamma}/\beta}\mathbf{1}_{(0,\infty)}(y)$$
In other words, Weibull random variable is a power transformed version of exponential random variable. And as $\gamma=1$, the Weibull degenerates to exponential.

\noindent{\bf Gamma}: Intuitively, gamma distribution captures the total interleaving time up to more than one appearances. We use two parameters $\alpha,\beta$ to define a gamma random variable and denote it as Gamma($\alpha,\beta$). If $X\sim$Gamma($\alpha,\beta$), then
$$f_X(x|\alpha,\beta) = \frac{x^{\alpha-1}e^{-x/\beta}}{\Gamma(\alpha)\beta^{\alpha}}\mathbf{1}_{(0,\infty)}$$

As we mentioned earlier, these three distributions are highly related to Poisson distribution in the sense that they describe the waiting time of a counting process given the number of desired observations while Poisson distribution captures the number of appearances given the amount of observing time. The two aspects are just two side of a coin, and we can use the following equation to relate them all together: Let $\{N(t)\}$ be a counting process and $T$ be the corresponding waiting time for a single event to happen. We have 
$$\{T>t\} = \{N(t)=0\}$$
If we write down the probability of each side and do some computation, we can derive a relationship between exponential distribution and Poisson distribution.



\end{document}
